{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1cAg8-AX-XqgPal1LTbpXrDG7YENPGx9X",
      "authorship_tag": "ABX9TyMaTiBxBRNuoXVMV2of3c5B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayush6233/Credit_score_assigner/blob/main/creditscore_for_defi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "vQfuW4mO91fE",
        "outputId": "1ebc256b-a53c-420e-a8f1-eb6fcfbdfab4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: colab_kernel_launcher.py [-h] [--contamination CONTAMINATION]\n",
            "                                [--n_estimators N_ESTIMATORS]\n",
            "                                input_json output_json\n",
            "colab_kernel_launcher.py: error: the following arguments are required: output_json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "2",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import argparse\n",
        "from collections import defaultdict\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "\n",
        "def parse_json_transactions(filepath: str) -> pd.DataFrame:\n",
        "    objs = []\n",
        "    buffer = \"\"\n",
        "    brace_count = 0\n",
        "    with open(filepath, \"r\") as f:\n",
        "        for line in f:\n",
        "            if not line.strip():\n",
        "                continue\n",
        "            brace_count += line.count(\"{\") - line.count(\"}\")\n",
        "            buffer += line\n",
        "            if brace_count == 0 and buffer.strip():\n",
        "                chunk = buffer.strip().rstrip(\",\")\n",
        "                try:\n",
        "                    obj = json.loads(chunk)\n",
        "                    objs.append(obj)\n",
        "                except json.JSONDecodeError:\n",
        "                    pass\n",
        "                buffer = \"\"\n",
        "    df = pd.json_normalize(objs)\n",
        "    return df\n",
        "\n",
        "\n",
        "def engineer_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    # Flatten actionData\n",
        "    ad_cols = [c for c in df.columns if c.startswith(\"actionData.\")]\n",
        "    if ad_cols:\n",
        "        rename_map = {c: c.split('.', 1)[1] for c in ad_cols}\n",
        "        df = df.rename(columns=rename_map)\n",
        "    amt_col = [c for c in df.columns if c == 'amount' or 'amount' in c and 'Price' not in c][0]\n",
        "    price_col = [c for c in df.columns if 'assetPriceUSD' in c][0]\n",
        "\n",
        "    df['amount'] = df[amt_col].astype(float)\n",
        "    df['assetPriceUSD'] = df[price_col].astype(float)\n",
        "    df['amountUSD'] = df['amount'] * df['assetPriceUSD']\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
        "    now = df['timestamp'].max()\n",
        "\n",
        "    agg = df.groupby('userWallet').agg(\n",
        "        total_deposit_usd=('amountUSD', lambda x: x[df.loc[x.index, 'action']=='deposit'].sum()),\n",
        "        total_borrow_usd =('amountUSD', lambda x: x[df.loc[x.index, 'action']=='borrow'].sum()),\n",
        "        total_repay_usd  =('amountUSD', lambda x: x[df.loc[x.index, 'action']=='repay'].sum()),\n",
        "        borrow_count     =('action', lambda x: (x=='borrow').sum()),\n",
        "        repay_count      =('action', lambda x: (x=='repay').sum()),\n",
        "        liquidation_count=('action', lambda x: (x=='liquidationcall').sum()),\n",
        "        tx_count         =('action', 'count'),\n",
        "        last_ts          =('timestamp', 'max')\n",
        "    )\n",
        "\n",
        "    # Ratios and flags\n",
        "    agg['repay_borrow_ratio'] = agg['total_repay_usd'] / (agg['total_borrow_usd'] + 1e-9)\n",
        "    agg['liquidation_ratio']  = agg['liquidation_count'] / (agg['borrow_count'] + 1e-9)\n",
        "\n",
        "    # Flash-loan rate\n",
        "    flash_rates = []\n",
        "    for wallet, grp in df.groupby('userWallet'):\n",
        "        borrows = grp[grp.action=='borrow']['blockNumber']\n",
        "        repays  = grp[grp.action=='repay']['blockNumber']\n",
        "        rate = borrows.isin(repays).mean() if not borrows.empty else 0.0\n",
        "        flash_rates.append((wallet, rate))\n",
        "    flash_df = pd.DataFrame(flash_rates, columns=['userWallet','flashloan_rate']).set_index('userWallet')\n",
        "    agg = agg.join(flash_df)\n",
        "\n",
        "    # Recency score\n",
        "    days_since = (now - agg['last_ts']).dt.days\n",
        "    agg['recency_score'] = np.exp(-0.1 * days_since)\n",
        "\n",
        "    # Activity volume\n",
        "    agg['activity_volume'] = np.log1p(agg['tx_count'])\n",
        "\n",
        "    # Select features for modeling\n",
        "    features = agg[['repay_borrow_ratio','liquidation_ratio',\n",
        "                    'flashloan_rate','recency_score','activity_volume']].fillna(0)\n",
        "    return features\n",
        "\n",
        "def score_with_isolation_forest(features: pd.DataFrame,\n",
        "                                 contamination: float = 0.01,\n",
        "                                 n_estimators: int = 200) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Trains an Isolation Forest on the feature set (unsupervised) and returns\n",
        "    a credit score between 0 and 1000 for each row in `features`.\n",
        "    \"\"\"\n",
        "    scaler = MinMaxScaler()\n",
        "    X_scaled = scaler.fit_transform(features)\n",
        "\n",
        "    model = IsolationForest(\n",
        "        n_estimators=n_estimators,\n",
        "        max_samples='auto',\n",
        "        contamination=contamination,\n",
        "        random_state=42\n",
        "    )\n",
        "    model.fit(X_scaled)\n",
        "\n",
        "    raw_scores = model.decision_function(X_scaled)  # higher = more normal\n",
        "    # Normalize raw_scores to [0,1]\n",
        "    min_s, max_s = raw_scores.min(), raw_scores.max()\n",
        "    norm_scores = (raw_scores - min_s) / (max_s - min_s)\n",
        "\n",
        "    # Scale to [0,1000]\n",
        "    credit_scores = (norm_scores * 1000).round().astype(int)\n",
        "    return credit_scores\n",
        "\n",
        "parser = argparse.ArgumentParser(\n",
        "    description='Compute 0â€“1000 credit scores for Aave v2 wallets from transaction history'\n",
        ")\n",
        "parser.add_argument('input_json', help='/content/drive/MyDrive/user-wallet-transactions.json')\n",
        "parser.add_argument('output_json', help='/content/drive')\n",
        "parser.add_argument('--contamination', type=float, default=0.01,\n",
        "                    help=0.05)\n",
        "parser.add_argument('--n_estimators', type=int, default=200,\n",
        "                    help=100)\n",
        "args = parser.parse_args()\n",
        "df_raw = parse_json_transactions(args.input_json)\n",
        "features = engineer_features(df_raw)\n",
        "\n",
        "scores = score_with_isolation_forest(\n",
        "    features,\n",
        "    contamination=0.01,\n",
        "    n_estimators=100\n",
        ")\n",
        "\n",
        "result = pd.DataFrame({\n",
        "    'userWallet': features.index,\n",
        "    'credit_score': scores\n",
        "})\n",
        "result.to_json(args.output_json, orient='records')\n",
        "print(f\"Scored {len(result)} wallets; output written to {args.output_json}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "0W_WI8bk-PsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "4ljdj8O-iRw2"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FYPnpvbuBV6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4BB9ENeSYpmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RCu_VTDkZoOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JYfj-XINZyBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r6saX3cfZ4YP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}